{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Behavioral Cloning** \n",
    "\n",
    "## Writeup Report\n",
    "\n",
    "The goals / steps in this project are the following:\n",
    "* Used the simulator to collect data of good driving behavior\n",
    "* Built a convolution neural network in Keras that predicts steering angles from images\n",
    "* Trained and validated the model with a training and validation set\n",
    "* Tested that the model successfully drives around track one without leaving the road\n",
    "* Summarized the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/center_1.jpg \"Center Image 1\"\n",
    "[image2]: ./examples/center_2.jpg \"Center Image 2\"\n",
    "[image3]: ./examples/left_1.jpg \"Left Image\"\n",
    "[image4]: ./examples/right_1.jpg \"Right Image\"\n",
    "[image5]: ./examples/turn1.jpg \"Turn Image 1\"\n",
    "[image6]: ./examples/turn2.jpg \"Turn Image 2\"\n",
    "[image7]: ./examples/turn3.jpg \"Turn Image 3\"\n",
    "\n",
    "## Rubric Points\n",
    "### Here I have considered the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "---\n",
    "### Files Included & Code Quality\n",
    "\n",
    "#### 1. It includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "* clone.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* run2.mp4 a video file showing the run on the first track, recorded using an external camera\n",
    "* writeup_report.md summarizing the results\n",
    "\n",
    "#### 2. It includes functional code\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing \n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n",
    "\n",
    "#### 3. The code is usable and readable\n",
    "\n",
    "The clone.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. The Deep Learning Model architecture employed\n",
    "\n",
    "My model uses a powerful deep learning architecture developed by Nvidia. It consists of a normalization layer followed by three convolution neural networks with 5x5 filter sizes and strides of two steps and valid padding and filter numbers for each of the convolutional layers as 24, 36 and 48. This is followed by two convolution layers of 64 filters of size 3x3 with padding again as valid. The next layer is the flatten layer followed by fully connected layers of 100, 50, 10 and then finally 1. The model was built using Keras sequential model library. \n",
    "\n",
    "#### 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "The model used image augmentation to reduce overfitting. The images received were flipped and the side camera images were taken into the training process to increase the amount of data in order to reduce overfitting. Furthermore, more data was collected by driving more laps around and was used in the model to reduce overfitting.\n",
    "\n",
    "The model was trained and validated on different data sets to ensure that the model was not overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.\n",
    "\n",
    "#### 3. Model parameter tuning\n",
    "\n",
    "The model used an adam optimizer, so the learning rate was not tuned manually. However, the steering correction was tuned because the model behaved very differently at different steering rates. The steering correction was the correction factor used in the steering angle data when the left and the right images were used as the center images. After several hit and trials, I finally landed on a value of 0.1, i.e. the steering angle is increased by 0.1 when a left camera image is used as a center image and decreased by 1 when a right camera image is used as a center image.\n",
    "\n",
    "#### 4. Appropriate training data\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. I used a combination of center lane driving, recovering from the left and right sides of the road, and several laps of driving around the corners and turns to give the model sufficient data. Furthermore, the images from the side cameras were used as the training images by adding a correction factor for the steering further helping the car on recovery from the sides. Then there were a few laps of training on the track with good driving to help the model play well in the end.\n",
    "\n",
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "The overall strategy for deriving a model architecture was to create a neural network deep enough for the model to vast number of images that the model will have to perform training on without overfitting.\n",
    "\n",
    "My first step was to use a convolution neural network model similar to the architecture used by Nvidia to develop their own self driving car. I thought this model might be appropriate because it is a model used on an actual self driving car and has performed well. The network looked deep enough with five layers of convolution and five layers of fully connected layers.\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. I found that my first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting.\n",
    "\n",
    "To combat the overfitting, I modified the model so that the mean squared error in the validation set also came down to the training set. In order to do that, I added more data into the model. I flipped the center driving images and simultaneously flipped the sign of steering measurements. I then used the images from the side cameras for the driver training by adding corrections to the steering angle.\n",
    "\n",
    "Then I collected more data by performing recovery driving from the sides and driving a few more laps on the center of the road.\n",
    "\n",
    "The final step was to run the simulator to see how well the car was driving around track one. There were a few spots where the vehicle fell off the track. To improve the driving behavior in these cases, I tuned the steering correction for the side cameras. I also cropped the camera images to reduce the effect of the pixels above the road line as it only caused disturbance in the learning process. However, in few of the tricky corners and turns, I had to add more data by retraining the car on those curves.\n",
    "\n",
    "At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road.\n",
    "\n",
    "#### 2. Final Model Architecture\n",
    "\n",
    "The final model architecture consisted of a normalization layer and a cropping layer followed by three convolution neural networks with 5x5 filter sizes and strides of two steps and valid padding and filter numbers for each of the convolutional layers as 24, 36 and 48. This is followed by two convolution layers of 64 filters of size 3x3 with padding again as valid. The next layer is the flatten layer followed by fully connected layers of 100, 50, 10 and then finally 1. The model was built using Keras sequential model library. \n",
    "\n",
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "To capture good driving behavior, I first recorded two laps on track one using center lane driving. Here is an example image of center lane driving:\n",
    "\n",
    "![alt text][image1]\n",
    "![alt text][image2]\n",
    "\n",
    "I also recorded the side image camera views and used them as center images with a correction factor in the steering.\n",
    "\n",
    "![alt text][image3]\n",
    "![alt text][image4]\n",
    "\n",
    "Then I repeated this process on track two in order to get more data points.\n",
    "\n",
    "I took more data on the turns to ensure smooth turning of the vehicle.\n",
    "\n",
    "![alt text][image5]\n",
    "![alt text][image6]\n",
    "![alt text][image7]\n",
    "\n",
    "After the collection process, I had 11000 number of data points. I then preprocessed this data by normalizing the image data. I also performed further image augmentation on the available images to further increase the number of images and added the images from the side cameras. \n",
    "\n",
    "\n",
    "I finally randomly shuffled the data set and put 20% of the data into a validation set. \n",
    "\n",
    "I used this training data for training the model. The validation set helped determine if the model was over or under fitting. The ideal number of epochs was 7 as evidenced by visualising the training and validation loss. The number of epochs was kept to a number that kept the validation loss decreasing. I used an adam optimizer so that manually training the learning rate wasn't necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
